is_train: True
ddp: False
stat: wandb
training_speakers: [2]
root_path: ./
out_path: ./outputs/
cache_path: datasets/cache/face_lml/
project: emage
wandb_run: face_lml_r1v4a4v4v4a4c4f1v4a4g1_test # face_a30b2_r1v4a4v4v4a4c4f1v4a4g1
data_path: ./emage_amass30_beat2ss/
e_path:  weights/AESKConv_240_100.bin
# test_ckpt: outputs/custom/face_a30b2_r1v4a4v4v4a4c4f1v4a4g1/epoch_0060_iter_03645.bin # outputs/custom/face_beat2ss_c256/epoch_0253_iter_03226.bin
test_ckpt: outputs/custom/face_lml_r1v4a4v4v4a4c4f1v4a4g1/epoch_0060_iter_00718.bin
data_path_1: ./EMAGE/
#torch_hub_path: datasets/hub/
additional_data: False
dataset: beat_sep
new_cache: False
ori_joints: beat_smplx_joints
tar_joints: beat_smplx_face
pose_rep: smplxflame_30
facial_rep: smplxflame_30
pose_norm: False
pose_fps: 30


vae_test_len: 64
vae_test_dim: 106
vae_test_stride: 20
vae_length: 256
vae_codebook_size: 256
vae_layer: 2
vae_grow: [1,1,2,1]
variational: False

pose_dims: 106
pose_length: 64
stride: 20
facial_dims: 100
word_index_num: 11195
word_dims: 300
batch_size: 64
lr_base: 3e-4
decay_epochs: 9999
model: motion_representation
g_name: VQVAEConvZero
#eval_model: motion_autoencoder
#e_name: HalfEmbeddingNet
trainer: aeface

# audio_f: 256
# a_pre_encoder: tcn_camn
# a_encoder: lp
# a_fix_pre: False

# freeze_wordembed: False
# word_f: 128
# t_pre_encoder: fasttext
# t_encoder: lp
# t_fix_pre: False

# motion_f: 256
# m_pre_encoder: lp
# m_encoder: lp
# m_fix_pre: False

# facial_f: 128
# f_pre_encoder: lp
# f_encoder: lp
# f_fix_pre: False

#m_decoder: lstm
#decode_fusion: cat
#n_layer: 2
#hidden_size: 512
rec_pos_weight: 1
rec_weight: 1
rec_vel_weight: 4
rec_acc_weight: 4
rec_ver_weight: 4
rec_ver_vel_weight: 4
rec_ver_acc_weight: 4
comm_weight: 4
grad_norm: 1
face_weight: 1
face_vel_weight: 4
face_acc_weight: 4
# rec_fac_weight: 1
#ita_weight: 0
#iwa_weight: 0
#fusion_mode: sum
epochs: 500
test_period: 1