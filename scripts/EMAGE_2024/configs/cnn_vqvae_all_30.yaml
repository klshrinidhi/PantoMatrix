is_train: True
ddp: False
stat: wandb
training_speakers: [2] #[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]
root_path: ./
out_path: ./outputs/
cache_path: datasets/cache/all_beat2ss/
project: emage
wandb_run: all_beat2ss_c512_cw4va4_gn1_test
data_path: ./emage_beat2ss/
e_path:  weights/AESKConv_240_100.bin
test_ckpt: outputs/custom/all_beat2ss_c512_cw4va4_gn1/epoch_0039_iter_03226.bin
data_path_1: ./EMAGE/
#torch_hub_path: datasets/hub/
additional_data: False
dataset: beat_sep
new_cache: False
ori_joints: beat_smplx_joints
tar_joints: beat_smplx_full
pose_rep: smplxflame_30
facial_rep: smplxflame_30
pose_norm: False
pose_fps: 30


vae_test_len: 64
vae_test_dim: 433
vae_test_stride: 20
vae_length: 512
vae_codebook_size: 512
vae_layer: 2
vae_grow: [1,1,2,1]
variational: False

pose_dims: 433
pose_length: 64
stride: 20
facial_dims: 100
word_index_num: 11195
word_dims: 300
batch_size: 64
lr_base: 3e-4
model: motion_representation
g_name: VQVAEConvZero
#eval_model: motion_autoencoder
#e_name: HalfEmbeddingNet
trainer: aeall
decay_epochs: 780
# audio_f: 256
# a_pre_encoder: tcn_camn
# a_encoder: lp
# a_fix_pre: False

# freeze_wordembed: False
# word_f: 128
# t_pre_encoder: fasttext
# t_encoder: lp
# t_fix_pre: False

# motion_f: 256
# m_pre_encoder: lp
# m_encoder: lp
# m_fix_pre: False

# facial_f: 128
# f_pre_encoder: lp
# f_encoder: lp
# f_fix_pre: False

#m_decoder: lstm
#decode_fusion: cat
#n_layer: 2
#hidden_size: 512
rec_vel_weight: 4
rec_acc_weight: 4
rec_weight: 1
rec_pos_weight: 1
rec_ver_weight: 1
comm_weight: 4
# rec_fac_weight: 1
#ita_weight: 0
#iwa_weight: 0
#fusion_mode: sum
grad_norm: 1
epochs: 800
test_period: 1